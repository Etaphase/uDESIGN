\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{hhline}
\usepackage{amsmath}
\usepackage{amsfonts}


\title{A Small Theorem on the Interval Approach Criterion for Systems of Linear Equations.}
\author{Isaac T Yonemoto}

\begin{document}

\maketitle

\section{Motivation}

The development of Unums encourages reformulation of computational mathematics to approach
numerical problems, keeping in mind traditional performance metrics, such as speed and energy
consumption, while still yielding mathematically accurate solutions.  Traditional numerical
systems, such as IEEE floating points, abandon accuracy for performance.  Symbolic systems
incur high calculation costs and still may encounter situations without closed form solutions.
Interval arithmetic can have exploding uncertainty under certain operations without clear
guidance on how to resolve this.  Unums, however, provide a natural solution to the exploding
uncertainty, by way of methods such as the Ubox method.

For solving systems of linear equations, the naive solution is to first perform a gauss-jordan
elimination and then whittle down the solution set using Uboxes.  This is inefficient and cannot
distinguish between a unit cell that contains a solution and a unit cell that merely happens to
be at the intersection of all of the hyperplanes.  Moreover, the search time proceeds with time
O(something large)

\section{The Interval Approach (uSlice) method}

To address this issue, I developed a strategy called the interval approach method.  The procedure
is as follows:  Select a dimension.  Partition a superset of the solved interval in this dimension 
with equal width (simplest to choose a power of two), called ``uslices''.  Apply the uslices as
values to the system of linear equations and measure the maximum error from the constant vector of the
linear equations.  Because the equations are linear, conceptually the ``outside'' slices should 
have greater error than the ``inside'' slices, with a few exceptions that are otherwise easily 
solved (e.g. an irrelevant dimension that trivially reduces to a smaller system of linear equations).

\section{Statement of the interval approach criterion}

First, some definitions:

Let $M$ be a matrix in $\mathbb{R}^{n\times n}$, and $\vec{v}, \vec{r} \in \mathbb{R}^n | M\vec{v} = \vec{r}$.

Let $\varPi$ be a closed box (n-orthotrope) in $\mathbb{R}^n$, with an equal tripartition of closed boxes across 
one dimension $\varPi = \bigcup\varPi_1 \varPi_2 \varPi_3$.
WOLOG, let the partitioning dimension be 1, so: 

\[ \vec{v} \in \varPi_1 = \left( \begin{array}{c}
\big[x_1, x_1 + \Delta x_1\big]  \\ \\
\big[x_2, x_2 + \Delta x_2\big]  \\ \\
\big[x_3, x_3 + \Delta x_3\big]  \end{array} \right); \varPi_2 = \left( \begin{array}{c}
\big[x_1 + \Delta x_1,  x_1 + 2\Delta x_1\big]  \\ \\
\big[x_2, x_2 + \Delta x_2\big]  \\ \\
\big[x_3, x_3 + \Delta x_3\big]  \end{array} \right); \varPi_3 = \left( \begin{array}{c}
\big[x_1 + 2\Delta x_1,  x_1 + 3\Delta x_1\big]  \\ \\
\big[x_2, x_2 + \Delta x_2\big]  \\ \\
\big[x_3, x_3 + \Delta x_3\big]  \end{array} \right);\] 

Define an ``heuristic function'' $d_{\alpha, \vec{r}} : \mathbb{R}^n \rightarrow \mathbb{R}^n$ for each dimension $\alpha$, where
$d_{\alpha, \vec{r}}(\vec{x}) = |(M\vec{x})_\alpha - r_\alpha|$.  This is effectively the dot product between the vector $\vec{x}$ and
the $\alpha$'th row of the matrix, or, crudely, `the error, across the partition, when attempting to solve the $\alpha$'th linear equation'.

We would like a criterion that guarantees that the characteristic shape of applying the heuristic function to each of these
intervals results in a diagnostic that can iteratively refine the partition $\varPi$.  The interval approach theorem shows
that the following condition:

\[ \Delta x_1 > \frac{\sum\limits_{i=2}^{n} |m_{\alpha,i}|\Delta x_i}{|m_{\alpha,1}|} \]

guarantees that $max(d_{\alpha, \vec{r}}(M\cdot\varPi_1)) < max(d_{\alpha, \vec{r}}(M\cdot\varPi_3))$.  As a result, any equal \emph{4-partition} of a closed
box that has $max(d_{\alpha, \vec{r}}(M\cdot\varPi_1)) > max(d_{\alpha, \vec{r}}(M\cdot\varPi_2))$ and $max(d_{\alpha, \vec{r}}(M\cdot\varPi_3)) < max(d_{\alpha, \vec{r}}(M\cdot\varPi_4))$
has a guarantee that $\vec{r}$ is in either $\varPi_2$ or $\varPi_3$, which iteratively reduces the bounds on the solution.

\section{Proof, n = 2}

\subsection{case $m_{\alpha,:} > 0$}

\setlength{\unitlength}{0.8cm}
\begin{picture}(6,4)
\thicklines
\put(1,1){\line(3,0){3}}
\put(1,3){\line(3,0){3}}
\put(1,1){\line(0,1){2}}
\put(2,1){\line(0,1){2}}
\put(3,1){\line(0,1){2}}
\put(4,1){\line(0,1){2}}
\put(1.1,1.1){$\vec{v}$}
\put(1,1){\circle*{0.15}}
\put(2,3){\circle*{0.15}}
\put(4,3){\circle*{0.15}}
\put(1.5,1.3){\circle*{0.1}}
\put(1.2,1.8){$\varPi_1$}
\put(2.2,1.8){$\varPi_2$}
\put(3.2,1.8){$\varPi_3$}
\put(0.6,0.6){$A$}
\put(1.8,3.2){$B$}
\put(3.9,3.2){$C$}
\end{picture}

\paragraph{Lemma: $max(d_{\alpha,\vec{r}}(\varPi_1))$ must be $d_{\alpha,\vec{r}}(\vec{A})$ or $d_{\alpha,\vec{r}}(\vec{B})$.}
WOLOG, let's take $\alpha = 1$ and label the row $(a\ b) \equiv (m_{1,1}\ m_{1,2})$.  For simplicity, we will identify $d = d_{\alpha,\vec{r}}$

Examine all points $\vec{x}$ where $v_1 < x_1 < B_1$, and $v_2 < x_2 < B_2$.  Crudely, this is the ``upper right sub-rectangle'' 
created within $\varPi_1$ by $\vec{v}$.  Compare $d(\vec{x})$ and $d(\vec{B})$.  

$d(\vec{x}) = |(M\vec{x} - \vec{r})_1| = |(M(\vec{v} + \delta\vec{x}) - M\vec{v})_1|$ for some positive vector $\delta\vec{x}$.  By linearity, this
$d(\vec{x}) = |(M\delta\vec{x})_1| = a(\delta{x})_1 + b(\delta{x})_2$

$d(\vec{A}) = |(M\vec{A} - \vec{r})_1| = |(M(\vec{v} + \delta\vec{x} + \delta'\vec{x}) - M\vec{v})_1|$ for some positive or zero vector $\delta'\vec{x}$.  By linearity, this
$d(\vec{A}) = |(M\delta\vec{x} + M\delta'\vec{x})_1| = a(\delta{x})_1 + b(\delta{x})_2 + a(\delta'{x})_1 + b(\delta'{x})_2$.  Since $\delta'\vec{x}$
is positive, $d(\vec{A}) \geq d(\vec{x})$ for all x in this upper right sub-rectangle, and so point B yields a maximum over this region.

Examine all points $\vec{x}$ where $A_1 < x_1 < v_1$, and $A_2 < x_2 < v_2$.  Crudely, this is the ``lower left sub-rectangle'' 
created within $\varPi_1$ by $\vec{v}$.  Compare $d(\vec{x})$ and $d(\vec{A})$.  

\end{document}
